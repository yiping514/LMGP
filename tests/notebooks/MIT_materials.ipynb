{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from lvgp_pytorch.optim import noise_tune\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lvgp_pytorch.models import LVGPR\n",
    "from lvgp_pytorch.optim import fit_model_scipy\n",
    "from lvgp_pytorch.utils.variables import CategoricalVariable\n",
    "from lvgp_pytorch.utils.input_space import InputSpace\n",
    "import timeit\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi']=150\n",
    "plt.rcParams['font.family']='serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mit_data = pd.read_csv(\"D:/APAR-E/Data/mit_data.csv\", delimiter=',', header=0)\n",
    "x = mit_data[[\"A\", \"M\", \"M'\", \"X\"]]\n",
    "comps = x.to_numpy()\n",
    "y = mit_data[[\"stability\"]]\n",
    "props = y.to_numpy()\n",
    "\n",
    "# configuration space\n",
    "config = InputSpace()\n",
    "A = CategoricalVariable(name=\"A\", levels=np.linspace(1,3,3))\n",
    "M = CategoricalVariable(name=\"M\", levels=np.linspace(1,6,6))\n",
    "M1 = CategoricalVariable(name=\"M1\", levels=np.linspace(1,5,5))\n",
    "S = CategoricalVariable(name=\"S\", levels=np.linspace(1,3,3))\n",
    "config.add_inputs([A, M, M1, S])\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "SEED = 1926\n",
    "set_seed(SEED)\n",
    "\n",
    "def get_prop(x_in):\n",
    "    x_rows = np.shape(x_in)[0]  # Number of x points\n",
    "    y_in = np.zeros(x_rows)\n",
    "    for i in range(x_rows):\n",
    "        idx = np.argwhere(np.all(x_in[i,:]-comps==0, axis=1))\n",
    "        y_in[i] = props[idx[0,0]]\n",
    "    return y_in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_x, test_x = train_test_split(x.values, train_size=0.7, test_size=0.3, random_state=SEED)\n",
    "\n",
    "train_y = get_prop(train_x)\n",
    "test_y = get_prop(test_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% MATLAB\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRMSE: 0.313\n",
      "Fit time:  135.45243390000002\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from LVGP_MATLAB_connector import LVGP_MATLAB\n",
    "start = timeit.default_timer()\n",
    "model_m = LVGP_MATLAB()\n",
    "model_m.fit(train_x, train_y[:,np.newaxis], ind_qual=config.qual_index)\n",
    "test_mean, test_std = model_m.predict(test_x)\n",
    "stop = timeit.default_timer()\n",
    "rrmse = np.sqrt(np.mean((test_y[:,np.newaxis]-test_mean)**2))/np.std(test_y)\n",
    "print('RRMSE: %5.3f'%rrmse.item())\n",
    "print('Fit time: ', stop - start)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Basic LVGP model\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRMSE: 0.315\n",
      "Fit time:  112.58912699999999\n"
     ]
    }
   ],
   "source": [
    "train_x = torch.tensor(train_x-1).double()\n",
    "test_x = torch.tensor(test_x-1).double()\n",
    "train_y = torch.tensor(train_y).double()\n",
    "test_y = torch.tensor(test_y).double()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "model = LVGPR(\n",
    "    train_x=train_x,\n",
    "    train_y=train_y,\n",
    "    qual_index=config.qual_index,\n",
    "    quant_index=config.quant_index,\n",
    "    num_levels_per_var=list(config.num_levels.values()),\n",
    "    noise=1,\n",
    "    quant_correlation_class=\"RBFKernel\",\n",
    "    fix_noise=False\n",
    ").double()\n",
    "\n",
    "reslist, nll_inc = fit_model_scipy(\n",
    "    model,\n",
    "    num_restarts=49,\n",
    "    options={'ftol':1e-6}\n",
    ")\n",
    "\n",
    "_ = model.eval()\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "with torch.no_grad():\n",
    "    test_mean, test_std = model.predict(test_x, return_std=True)\n",
    "rrmse = torch.mean((test_y-test_mean)**2).sqrt()/test_y.std()\n",
    "print('RRMSE: %5.3f'%rrmse.item())\n",
    "print('Fit time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Improved LVGP model\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL obtained from multi-start optimization....:   0.42\n",
      "NLL obtained from noise tuning strategy.......:   0.43\n",
      "RRMSE: 0.314\n",
      "Fit time:  27.402390000000025\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "model2 = LVGPR(\n",
    "    train_x=train_x,\n",
    "    train_y=train_y,\n",
    "    qual_index=config.qual_index,\n",
    "    quant_index=config.quant_index,\n",
    "    num_levels_per_var=list(config.num_levels.values()),\n",
    "    quant_correlation_class=\"RBFKernel\",\n",
    "    noise=1,\n",
    "    fix_noise=False\n",
    ").double()\n",
    "\n",
    "# optimize noise successively\n",
    "nll_inc_tuned,opt_history = noise_tune(\n",
    "    model2,\n",
    "    num_restarts=19, # num of starting points at the largest noise variance\n",
    "    options={'ftol':1e-8}\n",
    ")\n",
    "stop = timeit.default_timer()\n",
    "\n",
    "print('NLL obtained from multi-start optimization....: %6.2f'%nll_inc)\n",
    "print('NLL obtained from noise tuning strategy.......: %6.2f'%nll_inc_tuned)\n",
    "\n",
    "with torch.no_grad():\n",
    "    test_mean, test_std = model2.predict(test_x, return_std=True)\n",
    "rrmse = torch.mean((test_y-test_mean)**2).sqrt()/test_y.std()\n",
    "print('RRMSE: %5.3f'%rrmse.item())\n",
    "print('Fit time: ', stop - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (lvgp-pytorch)",
   "language": "python",
   "name": "pycharm-e4327f79"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": [
     "%% md\n",
     "\n",
     "# Optimizing properties for MITs using standard LVGP\n",
     "\n",
     "In this notebook, we will demonstrate training and analyzing standard LVGP models on the MITs' bandgap and stability dataset.\n"
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
