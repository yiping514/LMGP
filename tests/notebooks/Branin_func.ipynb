{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard LVGP regression models\n",
    "\n",
    "In this notebook, we will demonstrate training and analyzing standard LVGP models using the Branin function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gpytorch\n",
    "\n",
    "from lvgp_pytorch.models import LVGPR\n",
    "from lvgp_pytorch.optim import fit_model_scipy\n",
    "from lvgp_pytorch.optim.mll_noise_tune import noise_tune\n",
    "from lvgp_pytorch.utils.variables import NumericalVariable,CategoricalVariable,IntegerVariable\n",
    "from lvgp_pytorch.utils.input_space import InputSpace\n",
    "\n",
    "from typing import Dict\n",
    "from copy import deepcopy\n",
    "import timeit\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi']=150\n",
    "plt.rcParams['font.family']='serif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input space with variables:\n",
       "\n",
       "x, Type: Numerical, Range: [-5.0,10.0]\n",
       "t, Type: Categorical, Levels: {1.0, 2.0, 3.0, 4.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# configuration space\n",
    "config = InputSpace()\n",
    "x = NumericalVariable(name='x',lower=-5,upper=10)\n",
    "t = CategoricalVariable(name='t',levels=np.linspace(1,4,4))\n",
    "config.add_inputs([x,t])\n",
    "\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def branin(params:Dict)->float:\n",
    "    a, b, c, r, s, t1 = 1, 5.1/4/(np.pi**2), 5/np.pi, 6, 10, 1/8/np.pi\n",
    "    x = params[\"x\"]\n",
    "    t = (params[\"t\"]-1)*5.0\n",
    "    return a * (t - b * x**2 + c*x - r)**2 + s*(1-t1)*np.cos(x) + s\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 100 samples\n",
    "set_seed(1)\n",
    "num_samples = 20\n",
    "train_x = torch.from_numpy(\n",
    "    config.random_sample(np.random,num_samples)\n",
    ")\n",
    "train_y = [None]*num_samples\n",
    "\n",
    "for i,x in enumerate(train_x):\n",
    "    train_y[i] = branin(config.get_dict_from_array(x.numpy()))\n",
    "\n",
    "train_y = torch.tensor(train_y).double()\n",
    "\n",
    "\n",
    "# generate 1000 test samples\n",
    "num_samples = 1000\n",
    "test_x = torch.from_numpy(config.random_sample(np.random,num_samples))\n",
    "test_y = [None]*num_samples\n",
    "\n",
    "for i,x in enumerate(test_x):\n",
    "    test_y[i] = branin(config.get_dict_from_array(x.numpy()))\n",
    "    \n",
    "# create tensor objects\n",
    "test_y = torch.tensor(test_y).to(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.1702e-01, 1.0000e+00],\n",
       "        [7.2032e-01, 1.0000e+00],\n",
       "        [1.1437e-04, 1.0000e+00],\n",
       "        [3.0233e-01, 3.0000e+00],\n",
       "        [1.4676e-01, 3.0000e+00],\n",
       "        [9.2339e-02, 1.0000e+00],\n",
       "        [1.8626e-01, 2.0000e+00],\n",
       "        [3.4556e-01, 1.0000e+00],\n",
       "        [3.9677e-01, 1.0000e+00],\n",
       "        [5.3882e-01, 0.0000e+00],\n",
       "        [4.1919e-01, 0.0000e+00],\n",
       "        [6.8522e-01, 1.0000e+00],\n",
       "        [2.0445e-01, 0.0000e+00],\n",
       "        [8.7812e-01, 0.0000e+00],\n",
       "        [2.7388e-02, 1.0000e+00],\n",
       "        [6.7047e-01, 3.0000e+00],\n",
       "        [4.1730e-01, 3.0000e+00],\n",
       "        [5.5869e-01, 2.0000e+00],\n",
       "        [1.4039e-01, 1.0000e+00],\n",
       "        [1.9810e-01, 0.0000e+00]], dtype=torch.float64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a LVGP instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%% Matlab\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom LVGP_MATLAB_connector import LVGP_MATLAB\\ntrain_xm, train_ym, test_xm, test_ym = train_x.numpy(), train_y.numpy(), test_x.numpy(), test_y.numpy()\\n\\nstart = timeit.default_timer()\\nmodel_m = LVGP_MATLAB()\\nmodel_m.fit(train_xm, train_ym[:, np.newaxis], ind_qual=config.qual_index)\\ntest_mean, test_std = model_m.predict(test_xm)\\nstop = timeit.default_timer()\\nrrmse = np.sqrt(np.mean((test_ym[:,np.newaxis]-test_mean)**2))/np.std(test_ym)\\nprint('RRMSE: %5.3f'%rrmse.item())\\nprint('Fit time: ', stop - start)\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from LVGP_MATLAB_connector import LVGP_MATLAB\n",
    "train_xm, train_ym, test_xm, test_ym = train_x.numpy(), train_y.numpy(), test_x.numpy(), test_y.numpy()\n",
    "\n",
    "start = timeit.default_timer()\n",
    "model_m = LVGP_MATLAB()\n",
    "model_m.fit(train_xm, train_ym[:, np.newaxis], ind_qual=config.qual_index)\n",
    "test_mean, test_std = model_m.predict(test_xm)\n",
    "stop = timeit.default_timer()\n",
    "rrmse = np.sqrt(np.mean((test_ym[:,np.newaxis]-test_mean)**2))/np.std(test_ym)\n",
    "print('RRMSE: %5.3f'%rrmse.item())\n",
    "print('Fit time: ', stop - start)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create LVGP instance\n",
    "set_seed(4)\n",
    "start = timeit.default_timer()\n",
    "model = LVGPR(\n",
    "    train_x=train_x,\n",
    "    train_y=train_y,\n",
    "    qual_index=config.qual_index,\n",
    "    quant_index=config.quant_index,\n",
    "    num_levels_per_var=list(config.num_levels.values()),\n",
    "    quant_correlation_class=\"RBFKernel\",\n",
    "    noise=1, \n",
    "    fix_noise=False,\n",
    ").double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization using multiple random starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model with 50 different starts\n",
    "reslist,nll_inc = fit_model_scipy(\n",
    "    model,\n",
    "    num_restarts=49, # number of starting points\n",
    "    options={'ftol':1e-6} # options to L-BFGS\n",
    ")\n",
    "\n",
    "# set model to eval model; default is in train model\n",
    "_ = model.eval()\n",
    "stop = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRMSE : 0.160\n",
      "Fit time:  37.0511578\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "with torch.no_grad():\n",
    "    # set return_std = False if standard deviation is not needed \n",
    "    test_mean,test_std = model.predict(test_x,return_std=True)\n",
    "    \n",
    "# print RRMSE\n",
    "rrmse = torch.mean((test_y-test_mean)**2).sqrt()/test_y.std()\n",
    "print('RRMSE : %5.3f'%rrmse.item())\n",
    "print('Fit time: ', stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# plot latent values\\nn_fig = np.shape(config.qual_index)[0]\\nfig,axs = plt.subplots(1,n_fig,figsize=(10,4))\\n\\nfor i in range(n_fig):\\n    latents = model.lv_mapping_layers[i].latents.detach().numpy()\\n    _ = axs[i].plot(latents[:,0],latents[:,1],'k.')\\n    \\n    hyp = config.get_variable_by_idx(config.qual_index[i])\\n    # annotate the labels\\n    for j,level in enumerate(hyp.levels):\\n        _ = axs[i].annotate(\\n            str(level),latents[j,:],\\n            textcoords = 'offset points',\\n            xytext = (-1,3),\\n            size='8'\\n        )\\n        \\n    \\n    _ = axs[i].set_xlabel(r'$z_1$')\\n    _ = axs[i].set_ylabel(r'$z_2$')\\n    _ = axs[i].set_title(r'$%s$' %hyp.name)\\n    _ = axs[i].grid(alpha=0.5)\\n    _ = axs[i].set_aspect('equal', 'datalim')\\n\\nfig.tight_layout()\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "# plot latent values\n",
    "n_fig = np.shape(config.qual_index)[0]\n",
    "fig,axs = plt.subplots(1,n_fig,figsize=(10,4))\n",
    "\n",
    "for i in range(n_fig):\n",
    "    latents = model.lv_mapping_layers[i].latents.detach().numpy()\n",
    "    _ = axs[i].plot(latents[:,0],latents[:,1],'k.')\n",
    "    \n",
    "    hyp = config.get_variable_by_idx(config.qual_index[i])\n",
    "    # annotate the labels\n",
    "    for j,level in enumerate(hyp.levels):\n",
    "        _ = axs[i].annotate(\n",
    "            str(level),latents[j,:],\n",
    "            textcoords = 'offset points',\n",
    "            xytext = (-1,3),\n",
    "            size='8'\n",
    "        )\n",
    "        \n",
    "    \n",
    "    _ = axs[i].set_xlabel(r'$z_1$')\n",
    "    _ = axs[i].set_ylabel(r'$z_2$')\n",
    "    _ = axs[i].set_title(r'$%s$' %hyp.name)\n",
    "    _ = axs[i].grid(alpha=0.5)\n",
    "    _ = axs[i].set_aspect('equal', 'datalim')\n",
    "\n",
    "fig.tight_layout()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An improved optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLL obtained from multi-start optimization....:   1.13\n",
      "NLL obtained from noise tuning strategy.......:   1.13\n"
     ]
    }
   ],
   "source": [
    "set_seed(4)\n",
    "start = timeit.default_timer()\n",
    "\n",
    "model2 = LVGPR(\n",
    "    train_x=train_x,\n",
    "    train_y=train_y,\n",
    "    qual_index=config.qual_index,\n",
    "    quant_index=config.quant_index,\n",
    "    num_levels_per_var=list(config.num_levels.values()),\n",
    "    quant_correlation_class=\"RBFKernel\",\n",
    "    noise=1, \n",
    "    fix_noise=False\n",
    ").double()\n",
    "\n",
    "# optimize noise successively\n",
    "nll_inc_tuned,opt_history = noise_tune(\n",
    "    model2,\n",
    "    num_restarts=19, # num of starting points at the largest noise variance\n",
    "    options={'ftol':1e-8}\n",
    ")\n",
    "stop = timeit.default_timer()\n",
    "# \n",
    "print('NLL obtained from multi-start optimization....: %6.2f'%nll_inc)\n",
    "print('NLL obtained from noise tuning strategy.......: %6.2f'%nll_inc_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RRMSE : 0.153\n",
      "Fit time:  8.496377300000006\n"
     ]
    }
   ],
   "source": [
    "# prediction on test set\n",
    "with torch.no_grad():\n",
    "    # set return_std = False if standard deviation is not needed\n",
    "    # set include_noise = True, if noise variance is to be included\n",
    "    # in the posterior variance \n",
    "    test_mean2,test_std2 = model2.predict(test_x,return_std=True)\n",
    "    \n",
    "\n",
    "# print RRMSE\n",
    "rrmse = torch.mean((test_y-test_mean2)**2).sqrt()/test_y.std()\n",
    "print('RRMSE : %5.3f'%rrmse.item())\n",
    "print('Fit time: ', stop - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# plot latent values\\nfig,axs = plt.subplots(1,n_fig,figsize=(10,4))\\n\\nfor i in range(n_fig):\\n    latents = model2.lv_mapping_layers[i].latents.detach().numpy()\\n    _ = axs[i].plot(latents[:,0],latents[:,1],'k.')\\n    \\n    hyp = config.get_variable_by_idx(config.qual_index[i])\\n    # annotate the labels\\n    for j,level in enumerate(hyp.levels):\\n        _ = axs[i].annotate(\\n            str(level),latents[j,:],\\n            textcoords = 'offset points',\\n            xytext = (-1,3),\\n            size='8'\\n        )\\n        \\n    \\n    _ = axs[i].set_xlabel(r'$z_1$')\\n    _ = axs[i].set_ylabel(r'$z_2$')\\n    _ = axs[i].set_title(r'$%s$' %hyp.name)\\n    _ = axs[i].grid(alpha=0.5)\\n    _ = axs[i].set_aspect('equal', 'datalim')\\n\\nfig.tight_layout()\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# plot latent values\n",
    "fig,axs = plt.subplots(1,n_fig,figsize=(10,4))\n",
    "\n",
    "for i in range(n_fig):\n",
    "    latents = model2.lv_mapping_layers[i].latents.detach().numpy()\n",
    "    _ = axs[i].plot(latents[:,0],latents[:,1],'k.')\n",
    "    \n",
    "    hyp = config.get_variable_by_idx(config.qual_index[i])\n",
    "    # annotate the labels\n",
    "    for j,level in enumerate(hyp.levels):\n",
    "        _ = axs[i].annotate(\n",
    "            str(level),latents[j,:],\n",
    "            textcoords = 'offset points',\n",
    "            xytext = (-1,3),\n",
    "            size='8'\n",
    "        )\n",
    "        \n",
    "    \n",
    "    _ = axs[i].set_xlabel(r'$z_1$')\n",
    "    _ = axs[i].set_ylabel(r'$z_2$')\n",
    "    _ = axs[i].set_title(r'$%s$' %hyp.name)\n",
    "    _ = axs[i].grid(alpha=0.5)\n",
    "    _ = axs[i].set_aspect('equal', 'datalim')\n",
    "\n",
    "fig.tight_layout()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2187f0f2032fce2f19f6d7466df12b1d9bdb15d6a3443601df0e7624d2c8f8da"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
