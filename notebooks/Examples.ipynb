{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF_Wings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from lmgp_pytorch.models import LMGP\n",
    "from lmgp_pytorch.test_functions.multi_fidelity import multi_fidelity_wing\n",
    "from lmgp_pytorch.preprocessing import train_test_split_normalizeX\n",
    "from lmgp_pytorch.utils import set_seed\n",
    "from lmgp_pytorch.optim import fit_model_scipy\n",
    "\n",
    "###############Parameters########################\n",
    "random_state = 4\n",
    "set_seed(random_state)\n",
    "qual_index = {10:4}\n",
    "num={'0': 5000, '1': 10000, '2': 10000, '3': 10000}\n",
    "noise_std={'0': 0.5, '1': 1.0, '2': 1.5, '3': 2.0}\n",
    "############################ Generate Data #########################################\n",
    "X, y = multi_fidelity_wing(n = num, noise_std= noise_std, random_state = random_state)\n",
    "############################## train test split ####################################\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split_normalizeX(X, y, test_size = 0.99, \n",
    "    qual_index_val= qual_index, stratify= X[...,list(qual_index.keys())])\n",
    "############################### Model ##############################################\n",
    "model = LMGP(Xtrain, ytrain, qual_ind_lev=qual_index)\n",
    "############################### Fit Model ##########################################\n",
    "_ = fit_model_scipy(model)\n",
    "############################### Score ##############################################\n",
    "model.score(Xtest, ytest, plot_MSE=True, seperate_levels=True)\n",
    "############################### Latent Map ##############################################\n",
    "_ = model.visualize_latent()\n",
    "model.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Benchmarks: 1D, Multi-fidelity\n",
    "### Bias only model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lmgp_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlmgp_pytorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m LMGP\n\u001b[0;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlmgp_pytorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtest_functions\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtest_benchmarks\u001b[39;00m \u001b[39mimport\u001b[39;00m multi_fidelity_bias_only\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlmgp_pytorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split_normalizeX\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lmgp_pytorch'"
     ]
    }
   ],
   "source": [
    "from lmgp_pytorch.models import LMGP\n",
    "from lmgp_pytorch.test_functions.test_benchmarks import multi_fidelity_bias_only\n",
    "from lmgp_pytorch.preprocessing import train_test_split_normalizeX\n",
    "from lmgp_pytorch.utils import set_seed\n",
    "from lmgp_pytorch.optim import fit_model_scipy\n",
    "\n",
    "###############Parameters########################\n",
    "random_state = 4\n",
    "set_seed(random_state)\n",
    "qual_index = {1:3}\n",
    "num={'0':20, '1': 20, '2': 20}\n",
    "noise_std={'0': 0, '1': 0, '2': 0}\n",
    "############################ Generate Data #########################################\n",
    "X, y = multi_fidelity_bias_only(n = num, noise_std= noise_std, random_state = random_state)\n",
    "############################## train test split ####################################\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split_normalizeX(X, y, test_size = 0.9, \n",
    "    qual_index_val= qual_index, stratify= X[...,list(qual_index.keys())])\n",
    "############################### Model ##############################################\n",
    "model = LMGP(Xtrain, ytrain, qual_ind_lev=qual_index)\n",
    "############################### Fit Model ##########################################\n",
    "_ = fit_model_scipy(model)\n",
    "############################### Score ##############################################\n",
    "#model.score(Xtest, ytest, plot_MSE=True, seperate_levels=True)\n",
    "############################### Latent Map ##############################################\n",
    "#_ = model.visualize_latent()\n",
    "############################### Predict #############################################\n",
    "y_pred = model.predict(Xtest,return_std=False )\n",
    "print(\"y_pred =\", y_pred)\n",
    "############################## Visualization ########################################\n",
    "#model.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LMGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
